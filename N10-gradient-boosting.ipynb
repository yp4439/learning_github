{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"https://img.shields.io/badge/实验楼-开放机器学习课程-green.svg?style=popout-square\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度提升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作为机器学习的经典算法之一，梯度提升是一种集成算法。因其拥有出色的分类性能而得到许多数据科学家的青睐。也往往是许多选手在各大数据竞赛平台中参加比赛时首选的算法之一。是什么让它如此出色呢？本次实验将详细介绍其工作原理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 梯度提升\n",
    "- 提升树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 梯度提升介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习中，有一些算法通过常被称为弱模型，这里所说的“弱模型”指的是像决策树这样简单的基本模型，也指的是那些精度相对较差的模型，换句话说就是比随机模型好那么一点点的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先来思考一个[问题](http://www.cis.upenn.edu/~mkearns/papers/boostnote.pdf)：是否可以从大量相对较弱和简单的模型中通过某种手段而得到一个强大的模型? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如你想的一样，这个问题的[答案](http://www.cs.princeton.edu/~schapire/papers/strengthofweak.pdf)显然是肯定的。集成方法就是其中的一类，集成学习的算法有很多，先从最简单的开始—— AdaBoost 。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " AdaBoost 采用的是一种贪婪的学习方法。在算法学习时，会给数据样本的每个都会附一个权重值，每一个基分类器开始进行分类前，都会根据前一个分类器的分类误差来调节样本的权重值。然后通线性组合的方式把所有的基分类器集成起来得到一个强分类器。整个过程可以描述为下图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/d28/78f/7ba/d2878f7bad0340fc8002e5ba6d0879a5.jpg' width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上图中可知，在第一棵分类树（t=1）建立之后，会有三个蓝色的数据点被错分。因此在第二棵树建立的时候会增大这三个数据点的权值，以此类推。最终我们将三个基分类器结合起来(见下图)便得到了一个完美的分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/b2b/029/d89/b2b029d898f64bbbb158e15d29595969.png' width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整个过程要是用数学公式描述的话，整个过程如下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 首先，给每个样本一个初始的权重值：$ w_i^{(0)} = \\frac{1}{l}, i = 1, \\dots, l$\n",
    "- 遍历所有 $t = 1, \\dots, T$\n",
    "    * 训练基分类器 $ b_t$, 并令 $\\epsilon_t$ 等于分类误差.\n",
    "    * $\\alpha_t = \\frac{1}{2}ln\\frac{1 - \\epsilon_t}{\\epsilon_t}$.\n",
    "    * 更新样本权重: $ w_i^{(t)} = w_i^{(t-1)} e^{-\\alpha_t y_i b_t(x_i)}, i = 1, \\dots, l$.\n",
    "    * 归一化样本权重: $ w_0^{(t)} = \\sum_{j = 1}^k w_j^{(t)}, w_i^{(t)} = \\frac{w_i^{(t)}}{w_0^{(t)}}, i = 1, \\dots, l$.\n",
    "- 返回 $\\sum_t^{T}\\alpha_tb_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当进行迭代时，可以看到权重增加，特别是在类之间的边界上。[这里](https://www.youtube.com/watch?v=k4G2VCuOMMg)有一个关于 AdaBoost 的更详细的例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost 分类效果确实不错，但为何这一算法如此成功却[缺乏解释](https://www.cs.princeton.edu/courses/archive/spring07/cos424/papers/boosting-survey.pdf)。这会让一些人持怀疑态度，认为 AdaBoost 只是过度拟合而已。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过度拟合问题也确实存在，尤其是在当数据有非常怪异的异常值时，过拟合现象较为严重。因此，在这些类型的问题中，AdaBoost 是不稳定的。为解决这些问题，1999 年，杰罗姆·弗里德曼( Jerome Friedman )提出了 AdaBoost 的泛化版本——梯度提升( Machine )，也称为 GBM 。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " CART、 bootstrap 和许多其他算法都起源于斯坦福大学的统计部门。这些算法都非常的实用，但也有一些近年来研究工作尚未得到广泛的应用。例如，查看[glinternet](https://arxiv.org/abs/1308.2719)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在关于弗里德曼的录像资料不多。不过，有一个非常有趣的[访谈](https://www.youtube.com/watch?v=8hupHmBVvb0)，关于如何提出CART，以及CART如何解决统计学问题。Hastie 也有一个很棒的[讲座](https://www.youtube.com/watch?v=zBk3PK3g-Fc)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 AdaBoost 算法，虽然我们可以通过添加弱算法和逐步改进模型不准确部分数据来增强集成算法。但是，这还不够，例如 GBM 不仅建立在重新加权的数据点上，而且改进了它对整体目标函数梯度的逼近。这个概念极大地打开了集成算法的研究思路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://habrastorage.org/webt/h2/v4/k9/h2v4k9r-4yn4jwvwz99fbss4ghi.png\" width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GBM的历史"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自从 GBM 诞生以来，经过了 10 多年的时间，它才成为数据科学工具箱中必不可少的一部分。为了应用于不同的统计问题，GBM 拥有许多的扩展版本，例如：GLMboost 和 GAMboost 用于增强已有的 GAM 模型，CoxBoost 用于存活曲线，RankBoost 和 LambdaMART 用于排序问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "GBM 的许多实现也以不同的名称出现在不同的平台上。例如：随机 GBM、GBDT (梯度提升决策树)、GBRT (梯度提升回归树)、MART (多元加性回归树)等等。此外，由于 ML 社区又是各自为营，所以这使我们很难去知道 GBM 到底得到多广泛的应用，到底有多少个版本等问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时，GBM 也在搜索排序中也得到了广泛的应用。GBM 的加入使得搜索排序被看作为一个优化损失函数问题。最初，AltaVista 是第一批引入提升排名的公司之一。但很快，这些思路就传播到了雅虎、Yandex、必应等网站。从此之后，GBM 成为了主要的算法之一，不仅用于研究，而且也广泛用于工业生产中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/48a/ea4/fff/48aea4fffdbe4e5f9205ba81110e6061.jpg'  width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "许多的机器学习竞赛，尤其是 Kaggle，在促进普及算法的应用方面发挥了重要作用。因为 kaggle 提供了一个共同的平台，这使得数据科学家们可以在不同的数据科学问题上与来自世界各地的大量参与者竞争。人们可以在 kaggle上用真实数据上测试新的算法，让许多算法有机会“发光”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自 2011 年以来，在 Kaggle 的冠军访谈中，许多的获奖选手都提到自己使用了梯度提升算法。这也使得梯度提升变得流行起来。尤其是在 XGBoost 库出现之后。XGBoost 并不是一个新的、独特的算法;但其是一个经典 GBM 的高效实现版。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBM 的经历与许多机器学习算法一样：从被提出到成功的实践应用和大规模使用都花了许多年的时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先来看一个经典的监督学习问题，假设这里有一份数据集 $ \\left\\{ (x_i, y_i) \\right\\}_{i=1, \\ldots,n}$ , $ x $ 表示特征值，$y$ 表示目标值。构建模型就相当于构建一个函数  $f(x)$ ，用 $f(x)$ 去逼近目标值 $ y$。定义损失函数 $L(y,f(x))$ 来表示 预测值$f(x)$ 与真实值 $y$ 之间的距离。通过最小化损失函数，就可以得到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ \\large y \\approx \\hat{f}(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$\\large \\hat{f}(x) = \\underset{f(x)}{\\arg\\min} \\ L(y,f(x)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/img/topic10_help_with_func.png'  align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "在这里先不管 $f(x)$ 是具体哪一个模型或某个具体的表达式，仅假定损失函数 $L(y,f(x))$ 是可微的。如果损失函数取的是整个样本的均值，则最小化损失函数可以表达为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large  \\hat{f}(x) = \\underset{f(x)}{\\arg\\min} \\ \\mathbb {E} _{x,y}[L(y,f(x))]  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般情况下， $f(x)$ 的选择有很多，这意味着寻找最优的 $f(x)$ 会变得很困难。所以要对 $f(x)$ 加以限制，将其限制在一个函数空间内。假设模型的参数为 $\\theta $，定义 $\\theta \\in \\mathbb{R}^d $，则模型可描述为  $ \\large f(x, \\theta)$。所以现在寻找最优的 $f(x)$ 相当于要寻找一组参数 $\\theta $ ，使得损失函数 $L(y,f(x))$ 达到最小。用公式描述如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large \\hat{f}(x) = f(x, \\hat{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\hat{\\theta} = \\underset{\\theta}{\\arg\\min} \\ \\mathbb {E} _{x,y}[L(y,f(x,\\theta))] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于 $f(x)$  相对比较复杂。一般情况下，解析解不存在或无法直接求得。所以要使用迭代的方法来逼近参数。定义经验损失函数为 $ L_{\\theta}(\\hat{\\theta}) $ ，其计算公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large \\hat{\\theta} = \\sum_{i = 1}^M \\hat{\\theta_i} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large L_{\\theta}(\\hat{\\theta}) =  \\sum_{i = 1}^N L(y_i,f(x_i, \\hat{\\theta}))$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后,寻找一个合适的优化算法来最小化 $L_{\\theta}(\\hat{\\theta})$ 。梯度下降是最简单和最常用的优化方法。不过，在使用梯度下降算法时，需要参数进行初始化 $\\hat{\\theta_0}$。并定义迭代次数 $M$。整个优化过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义参数的初始值 $\\hat{\\theta} = \\hat{\\theta}_0$\n",
    "2. 对于每次迭代 $t = 1, \\dots, M$ 重复步骤3到7:\n",
    "1. 为当前的近似 $\\hat{\\theta}$ 计算损失函数的梯度值 \n",
    "$\\nabla L_{\\theta}(\\hat{\\theta}) = \\left[\\frac{\\partial L(y, f(x, \\theta))}{\\partial \\theta}\\right]_{\\theta = \\hat{\\theta}}$\n",
    "2. 通过计算梯度来设置当前的近似\n",
    "$\\hat{\\theta_t} \\leftarrow −\\nabla L_{\\theta}(\\hat{\\theta})$\n",
    "3. 更新参数 \n",
    "$\\hat{\\theta} \\leftarrow \\hat{\\theta} + \\hat{\\theta_t} = \\sum_{i = 0}^t \\hat{\\theta_i} $\n",
    "3. 保存近似结果 \n",
    "$\\hat{\\theta} = \\sum_{i = 0}^M \\hat{\\theta_i} $\n",
    "4.得到最终的函数 $\\hat{f}(x) = f(x, \\hat{\\theta})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过梯度下降优化模型的过程如下图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/2b5/5d6/90d/2b55d690d99e4ec0976b360aae6ce4df.jpg'   align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 函数梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上述的推导过程中，是通过不断的迭代来更新逼近函数 $ \\hat{f}(x)$ 。在函数梯度下降中，将这种逼近表述为增量改进之和，每个改进都是一个函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\hat{f}(x) = \\sum_{i = 0}^M \\hat{f_i}(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里假设所有的 $\\hat{f_i}(x)$ 被限制在某个函数空间中，即 $\\hat{f}(x) = h(x, \\theta)$。最终的模型可能比这个函数空间中的任何模型都要复杂。在每一步迭代中，需要选择最优系数 $\\rho_t$和 $\\theta_t$ 来使 $\\hat{f_t}(x)$ 达到最优。迭代过程如下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\hat{f}(x) = \\sum_{i = 0}^{t-1} \\hat{f_i}(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large (\\rho_t,\\theta_t) = \\underset{\\rho,\\theta}{\\arg\\min} \\ \\mathbb {E} _{x,y}[L(y,\\hat{f}(x) +  \\rho \\cdot h(x, \\theta))],$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\hat{f_t}(x) = \\rho_t \\cdot h(x, \\theta_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里仅以一般形式定义了模型，如果知道了损失函数的梯度表达式，就可以通过训练数据来优化模型，使其预测和梯度更相关。换句话说，我们将基于预测结果和这些残差的最小平方差来纠正预测结果。因此，模型的优化可以使用以下公式描述："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large \\hat{f}(x) = \\sum_{i = 0}^{t-1} \\hat{f_i}(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large r_{it} = -\\left[\\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)}\\right]_{f(x)=\\hat{f}(x)}, \\quad \\mbox{for } i=1,\\ldots,n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\theta_t = \\underset{\\theta}{\\arg\\min} \\ \\sum_{i = 1}^{n} (r_{it} - h(x_i, \\theta))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\rho_t = \\underset{\\rho}{\\arg\\min} \\ \\sum_{i = 1}^{n} L(y_i, \\hat{f}(x_i) + \\rho \\cdot h(x_i, \\theta_t))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/img/topic10_regression_for_everybody.jpg'   align='center' width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friedman 的经典 GBM 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 1999 年, Jerome Friedman 提出了一种经典的 GBM 算法。它是一种监督算法，其组成部分如下:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据集 $ \\left\\{ (x_i, y_i) \\right\\}_{i=1, \\ldots,n}$;\n",
    "- 迭代次数 $M$;\n",
    "- 损失函数 $ L(y, f)$ ;\n",
    "- 函数空间 $h(x, \\theta)$ 以及训练过程;\n",
    "- 函数空间 $ h(x, \\theta)$ 的超参数;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为寻找最优 $f_t(x)$ 需要知道 $f_{t-1}(x)$ 。那么 $ f_0(x)$ 是如何计算的呢？ 一般情况下，使用一个常数 $ \\gamma$ 和 最优系数 $\\rho $ 来搜索最优的  $ f_0(x)$ 。整个 GBM 运行过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 使用常数值初始化GBM $ \\hat{f}(x) = \\hat{f}_0, \\hat{f}_0 = \\gamma,  \\gamma \\in \\mathbb{R}$,\n",
    "$ \\hat{f}_0 = \\underset{\\gamma}{\\arg\\min} \\ \\sum_{i = 1}^{n} L(y_i, \\gamma)$\n",
    "2. 对于每次迭代 $ t = 1, \\dots, M$, 重复逼近过程:\n",
    "1. 计算伪残查 $r_t$\n",
    "$r_{it} = -\\left[\\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)}\\right]_{f(x)=\\hat{f}(x)}, \\quad \\mbox{for } i=1,\\ldots,n$\n",
    "2. 通过伪残差 $\\left\\{ (x_i, r_{it}) \\right\\}_{i=1, \\ldots,n}$ 构建基算法$\\large h_t(x)$ \n",
    "3. 通过$ h_t(x)$ 寻找最优系数\n",
    "$\\rho_t = \\underset{\\rho}{\\arg\\min} \\ \\sum_{i = 1}^{n} L(y_i, \\hat{f}(x_i) +  \\rho \\cdot h(x_i, \\theta))$\n",
    "4. 保存 $\\hat{f_t}(x) = \\rho_t \\cdot h_t(x)$\n",
    "5. 更新 $\\hat{f}(x) \\leftarrow \\hat{f}(x) + \\hat{f_t}(x) = \\sum_{i = 0}^{t} \\hat{f_i}(x)$\n",
    "\n",
    "3. 组成最终的模型 \n",
    "$\\hat{f}(x) = \\sum_{i = 0}^M \\hat{f_i}(x) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GBM工作原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面主要讲述了 GBM 的数学描述。现在通过例子来详细说明其是如何工作的。在这个例子中，需要重构一个带噪声的函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large y = cos(x) + \\epsilon, \\epsilon \\sim \\mathcal{N}(0, \\frac{1}{5}), x \\in [-5,5]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/9fe/04d/7ba/9fe04d7ba5a645d49fc6aa3e875c8c41.jpg'   align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个回归问题，所以损失函数选择均方误差损失函数。生成 300 对观测数据，并使用深度为 2 的决策树进行近似。 GBM 的参数设置如下:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据集 $\\left\\{ (x_i, y_i) \\right\\}_{i=1, \\ldots,300}$ ✓\n",
    "- 迭代次数 $M = 3$ ✓;\n",
    "- 均方差损失函数 $L(y, f) = (y-f)^2$ ✓\n",
    "-  $ L(y, f) = L_2$ 的梯度以及残差 $r = (y - f)$ ✓;\n",
    "- 基算法决策树 $ h(x)$ ✓;\n",
    "- 决策树的超参数，书的深度为2 ✓;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于均方差损失函数来说，初始化常数 $\\gamma$ 和系数  $\\rho_t$ 非常简单。仅需要将 $\\rho_t$ 设置为 1，而 $\\gamma$ 设置为下式即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\large \\gamma = \\frac{1}{n} \\cdot \\sum_{i = 1}^n y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行 GBM 算法，并绘制两种图形：如下图所示，蓝色的图表示当前拟合模型；绿色的图表示在伪残差上构建的每棵树。图的编号对应于迭代次数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/edb/328/98a/edb32898ad014d8d95782759d11f63fb.png'   align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上图可以看到，到第二次迭代时，模型已经能够拟合出数据的基本形式。然而，在第一次迭代时，算法只构建出了 $x \\in [-5, -4]$ 之间的数据。这是由于决策树模型没有足够的深度来同时构建一个对称的分支，并且它首先关注误差较大的左边的分支上。因此，右分支只出现在第二次迭代之后。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上图显示的迭代过程可知，整个过程正如预期的那。在每一步中，伪残差都在减小，而 GBM 在每次迭代中都越来越好地逼近原始数据。但是，决策树本身的构造使其不能近似连续函数，这意味着在本例中 GBM 不是最理想的。如果想要直观地理解 GBM 模型的拟合过程，可以通过一些可视化工具来进行可视化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/779/3e0/e66/7793e0e66b7d4871b6391a94cd5d4cf2.jpg'   align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想要求解一个分类问题，而不是回归问题，那应该怎么做呢？首先选择一个合适的损失函数 $L(y,f)$ 很重要。因为损失函数决定了模型将如何优化，以及最终会得到什么样的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说， 并不需要自己去发明一个损失函数，这些工作研究人员已经替我们做了。现在来探索用于最常见的两种目标的损失函数：回归和二分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回归损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于回归问题，通常对于不同的问题，不同的数据，选择的损失函数也不同。最常见的回归损失函数是"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  $ L_2$ 损失或高斯损失函数. 这一经典的条件平均数是最简单也是最常见的情形。如果没有额外信息，也不要求模型的鲁棒性，那么可以使用高斯损失。公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large L(y, f) = (y - f)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $L_1$ 损失或拉普拉斯损失。事实上它定义了条件中位数。通常，中位数对离群值的鲁棒性更好，所以这一损失函数在某些情形下也表现更好。但对大偏差的惩罚不像 $ L_2$ 那么大。公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large L(y, f) = |y - f|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $ L_q$ 损失或分位数损失.  $L_q$ 使用分位数而不是中位数。公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large \\begin{equation}  L(y, f) =\\left\\{   \\begin{array}{@{}ll@{}}     (1 - \\alpha) \\cdot |y - f|, & \\text{if}\\ y-f \\leq 0 \\\\     \\alpha \\cdot |y - f|, & \\text{if}\\ y-f >0  \\end{array}\\right. \\end{equation}, \\alpha \\in (0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这三种损失函数的函数图如下图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/6d5/e3a/09c/6d5e3a09c703491b947fde851e412ac0.png' width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 $L_q$ 损失函数来进行实验，继续使用前文所构建的数据。GBM 的实验参数设置如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据 $\\left\\{ (x_i, y_i) \\right\\}_{i=1, \\ldots,300}$ ✓\n",
    "- 迭代次数 $ M = 3$ ✓;\n",
    "- 损失函数 $  \\begin{equation}   L_{0.75}(y, f) =\\left\\{\n",
    "\\begin{array}{@{}ll@{}}    0.25 \\cdot |y - f|, & \\text{if}\\ y-f \\leq 0 \\\\     0.75 \\cdot |y - f|, & \\text{if}\\ y-f >0   \\end{array}\\right. \\end{equation} $ ✓;\n",
    "- 梯度 $L_{0.75}(y, f)$, $\\alpha = 0.7$  \n",
    "- 基算法 $ h(x)$ 为决策树✓;\n",
    "- 决策树超参数: depth =  2 ✓;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一次逼近需要 $y$ 的分位数，但这里并不知道最佳参数该取什么值，所以使用标准的线搜索。过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/0e6/7dd/614/0e67dd614076499e91c8c4238457ae4d.png'   align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，在每次迭代中， $r_{i} $ 只取 2 个可能的值，但是 GBM 仍然能够拟合初始的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说， 使用 $L_q$ 损失函数的 GBM 的结果等价于使用 $L_2$ 损失函数的 GBM 加上约 0.135 的偏置。但是如果使用的是90%分位数的话，那我们将没有足够的数据，因为样本类别变得极不平衡。在处理非标准问题时，需要记住这一点。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人们为回归任务开发了许多损失函数。例如，鲁棒性极强的 [Huber 损失函数](https://en.wikipedia.org/wiki/Huber_loss)。对于少数异常值，Huber 损失函数的工作方式是 $ L_2$，但异常值超过阈值之后，损失函数将更改为$L_1$。这会减少异常值的影响，并更加关注整体情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了更好理解损失函数，通过一个例子来说明。首先，实验数据由函数 $ y = \\frac{sin(x)}{x}$ 生成，并添加来自正常分布和Bernulli 分布的混合噪声。图 A-D 显示的是损失函数，图 F-H 显示的是相应的 GBM 拟合过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/130/05b/222/13005b222e8a4eb68c3936216c05e276.jpg'   align='center'> [源](https://habrastorage.org/web/130/05b/222/13005b222e8a4eb68c3936216c05e276.jpg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个例子中，使用样条曲线作为基算法。这也说明了，梯度提升中的基算法不一定是决策树。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上图中可以清楚地看到 $L_2$ 损失函数、$L_1$ 损失函数和 Huber 损失函数之间的区别。如果我们为 Huber 损失函数选择最优的参数，则可以得到更好的拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然 Huber 损失函数的效果很好。但是，Huber 损失函数只被非常少的流行库支持。例如，XGBoost不支持。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，让我们看看二进制分类问题 $ y \\in \\left\\{- 1,1 \\right\\}$。从技术上讲，此类问题也可以使用 $ L_2$ 损失来解决这个问题，但是这不是正规的做法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标变量的分布 $ y \\in \\left\\{- 1,1 \\right\\}$ 要求损失函数需要使用对数似然，常见的对数似然损失函数如下:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 逻辑损失或伯努利损失。该损失函数不仅要优化损失，同时要类别之间区别得更开。所以它甚至会惩罚正确预测的分类。公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large L(y, f) = log(1 + exp(-2yf))$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AdaBoost 损失。 与逻辑损失相似，但对错误的预测有更为严重的指数惩罚。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large L(y, f) = exp(-yf)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/bf5/9de/dcf/bf59dedcfd9d49b18e89ce342b09ce69.png' width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在来看一个例子。使用符号函数构建实验数据，如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/e72/513/78b/e7251378bf6d459ab1aeea7a1f1996a1.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先来探索将逻辑损失作为损失函数的模型。GBM 的实验参数如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 实验数据 $\\left\\{ (x_i, y_i) \\right\\}_{i=1, \\ldots,300}, y_i \\in \\left\\{-1, 1\\right\\}$ ✓\n",
    "- 迭代次数 $M = 3$ ✓;\n",
    "- 损失函数为逻辑损失函数, 其梯度为:\n",
    "$ r_{i} = \\frac{2 \\cdot y_i}{1 + exp(2 \\cdot y_i \\cdot \\hat{f}(x_i)) }, \\quad \\mbox{for } i=1,\\ldots,300$ ✓;\n",
    "- 基算法为决策树 $ h(x)$ ✓;\n",
    "- 决策树的超参数: depth = 2 ✓;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个例子中，算法的初始化有点困难。首先，数据的类别不平衡，负类为 63%，正类为 37%。其次，损失函数的初始化没有已知的解析公式，所以只能通过搜索来查找 $ \\hat{f_0} = \\gamma$，不同 $\\gamma$ 值对应的损失函数值如下图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/f8a/054/702/f8a05470271448d9bc0d4dc3e524a571.png' width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上图可知，最优初始近似是 -0.273 左右。你可能已经猜到它是负数，因为样本中负类的数量要比正类多很多。接下来对 GBM 模型进行优化，过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/7b4/ab0/5fa/7b4ab05fa0a543bfad94950e47f91568.png'   align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上图所示，该算法成功地将红色点数据和蓝色点数据分离。你可以看到“较低”区域是如何分隔的，因为决策树对正确预测负类更有信心。此外，还可以看到模型如何拟合混合分类。很明显，模型得到了大量正确分类的观测，一些误差较大的观测则可能是数据中的噪声所导致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候，我们需要一个更具体的损失函数来解决问题。例如，在金融时间序列中，我们可能想要给予时间序列中较大的波动更大的权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/0c0/ad0/3a4/0c0ad03a4c4b46bfa5bcd5101678c9c4.jpg'   align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有些人可能想要发明他们自己的损失函数，写出它的梯度，并仔细检查这个函数是否满足所需的属性。然而，有很大的几率会在某处犯下错误，导致计算困难，花费过量时间来排除错误。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对这一问题，人们提出了一种非常简单的做法：对观测结果进行加权。换句话说，如果知道数据的某个子集对模型更重要，那么可以直接给它们分配较大的权重 $w(x, y)$。权重通常需满足以下条件："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large w_i \\in \\mathbb{R}, $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large w_i \\geq 0 \\quad \\mbox{for } i=1,\\ldots,n,$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\sum_{i = 1}^n w_i > 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加权能够显著降低调整损失函数的时间。此外，这还可以充分发挥你的创造性。比如，简单地加上标量权重："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large  L_{w}(y,f) = w \\cdot L(y,f)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large r_{it} =   - w_i \\cdot \\left[\\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)}\\right]_{f(x)=\\hat{f}(x)} \\quad \\mbox{for } i=1,\\ldots,n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很明显，对于任意权重，我们并不知道模型的统计学性质。通常，将权重与值 $y$ 联系起来可能会变得过于复杂。例如，使用正比于 $|y|$ 的权重在 $L1$ 损失和 $L2$ 损失中是不等价的，因为梯度不考虑预测本身的值: $\\hat{f}(x)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先来为数据添加一些非常奇特的权重。然后定义一个非对称的加权函数，如下:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large \\begin{equation} w(x) =\\left\\{   \\begin{array}{@{}ll@{}}     0.1, & \\text{if}\\ x \\leq 0 \\\\     0.1 + |cos(x)|, & \\text{if}\\ x >0 \\end{array}\\right. \\end{equation} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/8c2/1b1/aa4/8c21b1aa47134f7aa46b15ef910369b2.png'   align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过这些权重，我们希望得到两个属性: $x$ 的负值细节更少和形成类似于初始余弦的函数。这里使用上一个例子的 GBM 模型，得到的结果如下:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/afc/cca/72a/afccca72a0774990b685de37b0fe9d9f.png'   align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上图可知，基本达到了预期的结果。首先，第一次迭代上的伪残差有着很大的差距，它们看起来几乎像初始余弦函数。其次，函数图的左侧往往被忽略，而右侧的权重更大。最后，在第三次迭代中模型得到了更多的关注，并开始与原始余弦函数相似也开始有点过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加权是一个强大但有风险的工具。可以使用它来控制模型的属性。如果你想优化损失函数，可以先尝试对观测结果进行加权。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本文中，我们有意省略了有关 GBM 正则化、随机性和超参数的问题，且在整个过程中仅使用了少 3 次迭代，这也并非偶然。如果使用30棵树而不是3棵，模型可能会因为复杂都过高而过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般情况下，良好的拟合如下图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/img/topic10_good_fit.png'   align='center' width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果模型在训练时过度关注那些异常值点，这往往也会导致其过拟合，如下图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/img/topic10_overfitting.png'   align='center' width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30 棵决策树的拟合结果如下图所示，在训练集上得损失为 0 ，而在测试集上得损失为 0.664。这说明模型在训练集上过拟合了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/web/27f/0f5/3be/27f0f53be9424cb1afaffb9a0e32909f.jpg'   align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本实验中，主要讲述了梯度增强背后的理论。GBM 不仅是一种特定的算法，也是一种建立模型集合的常用方法。此外，可以通过使用不同的损失函数和不同的加权函数来训练大量的模型。以此，该方法具有足够的灵活性和可扩展性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实践和机器学习相关竞赛表明，除了图像、音频和非常稀疏的数据外，在许多的标准问题中，GBM 通常是最有效的算法。此外，GBM 还有许多用于强化学习的改编版本,而且计算机视觉中的维奥拉-琼斯算法也是基于 AdaBoost 的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<i class=\"fa fa-link\" aria-hidden=\"true\"> 相关链接</i> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [GBM 教程](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3885826/)\n",
    "- [梯度提升树介绍](http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf) \n",
    "- [维基百科](https://en.wikipedia.org/wiki/Gradient_boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://doc.shiyanlou.com/document-uid214893labid7506timestamp1545810029884.png\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
